{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamd1985/Deep-Q-Learning-Applied-to-Algorithmic-Trading/blob/main/drl_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaDoHbxVH0CW"
      },
      "source": [
        "# Deep Q-Learning Applied to Algorithmic Trading\n",
        "\n",
        "<a href=\"https://www.kaggle.com/addarm/unsupervised-learning-as-signals-for-pairs-trading\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM59cTClH0CZ"
      },
      "source": [
        "INTRO\n",
        "\n",
        "\n",
        "This deep learning network was inspired by the paper:\n",
        "```BibTeX\n",
        "@article{theate2021application,\n",
        "  title={An application of deep reinforcement learning to algorithmic trading},\n",
        "  author={Th{\\'e}ate, Thibaut and Ernst, Damien},\n",
        "  journal={Expert Systems with Applications},\n",
        "  volume={173},\n",
        "  pages={114632},\n",
        "  year={2021},\n",
        "  publisher={Elsevier}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import google.colab\n",
        "\n",
        "  !sudo apt-get update\n",
        "  !sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "  !pip install 'imageio==2.4.0'\n",
        "  !pip install pyvirtualdisplay\n",
        "  !pip install tf-agents[reverb]\n",
        "  !pip install pyglet\n",
        "  !pip install tf-keras\n",
        "\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4-GoceIIfT_",
        "outputId": "8bf51853-d9fd-46e6-9806-5f7c87e47b98"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.83)] [Waiting for headers] [Wai\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcont\r                                                                               \rHit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "freeglut3-dev is already the newest version (2.8.1-6).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Requirement already satisfied: imageio==2.4.0 in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.0) (1.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.0) (9.4.0)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: tf-agents[reverb] in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.2.1)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.5.0)\n",
            "Requirement already satisfied: gym<=0.23.0,>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.25.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (9.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.16.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (3.20.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions==4.5.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (4.5.0)\n",
            "Requirement already satisfied: pygame==2.1.3 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.1.3)\n",
            "Requirement already satisfied: tensorflow-probability~=0.23.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.23.0)\n",
            "Requirement already satisfied: rlds in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: dm-reverb~=0.14.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (0.14.0)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (0.1.8)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.10/dist-packages (from dm-reverb~=0.14.0->tf-agents[reverb]) (1.5.2)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (23.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-agents[reverb]) (2.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from tensorflow-probability~=0.23.0->tf-agents[reverb]) (4.4.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-agents[reverb]) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from portpicker->dm-reverb~=0.14.0->tf-agents[reverb]) (5.9.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-agents[reverb]) (3.2.2)\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.10/dist-packages (2.0.14)\n",
            "Requirement already satisfied: tf-keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GJiIs_h-H0Ca",
        "outputId": "b8d9467f-6d32-4f8d-b1ee-d394f081e765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Kaggle or Collab...\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.37)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.25.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.4)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.0)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (14.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.25.2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1' # KERAS 2 only for tfagents\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "IS_KAGGLE = os.getenv('IS_KAGGLE', 'True') == 'True'\n",
        "if IN_COLAB or IS_KAGGLE:\n",
        "    # Kaggle confgs\n",
        "    print('Running in Kaggle or Collab...')\n",
        "    %pip install scikit-learn\n",
        "    %pip install tensorflow\n",
        "    %pip install tqdm\n",
        "    %pip install matplotlib\n",
        "    %pip install python-dotenv\n",
        "    %pip install yfinance\n",
        "    %pip install pyarrow\n",
        "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "        for filename in filenames:\n",
        "            print(os.path.join(dirname, filename))\n",
        "\n",
        "    DATA_DIR = \"/kaggle/input/DATASET\"\n",
        "else:\n",
        "    DATA_DIR = \"./data/\"\n",
        "    print('Running Local...')\n",
        "\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import BDay\n",
        "\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "import tensorflow as tf\n",
        "from tf_agents.environments import py_environment, utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import py_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import py_tf_eager_policy\n",
        "from tf_agents.policies import random_tf_policy\n",
        "\n",
        "import reverb\n",
        "from tf_agents.replay_buffers import reverb_replay_buffer\n",
        "from tf_agents.replay_buffers import reverb_utils\n",
        "\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "R9gEmFr8H0Ce"
      },
      "outputs": [],
      "source": [
        "START_DATE = \"2017-01-01\"\n",
        "SPLIT_DATE = '2018-1-1' # Turning point from train to tst\n",
        "END_DATE = \"2019-12-31\" # pd.Timestamp(datetime.now() - BDay(1)).strftime('%Y-%m-%d')\n",
        "DATA_DIR = \"./data\"\n",
        "INDEX = \"Date\"\n",
        "TARGET = 'TSLA'\n",
        "TICKER_SYMBOLS = [TARGET]\n",
        "INTERVAL = \"1d\"\n",
        "\n",
        "MODELS_PATH = './models'\n",
        "LOGS_PATH = './logs'\n",
        "\n",
        "ACT_LONG = 2\n",
        "ACT_HOLD = 1\n",
        "ACT_SHORT = 0\n",
        "\n",
        "CAPITAL = 100\n",
        "FEES = 0.1 / 100\n",
        "\n",
        "FEATURES = [\"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
        "STATE_LEN = 1\n",
        "OBS_SPACE = (STATE_LEN)*len(FEATURES)\n",
        "ACT_SPACE = 2\n",
        "\n",
        "BATCH_SIZE = 64 # OBS_SPACE * 100\n",
        "LEARN_RATE = 1e-3\n",
        "TOTAL_ITERS = 10 # 10000\n",
        "EPISODES = 10\n",
        "INIT_COLLECT = 10 # 100\n",
        "TOTAL_COLLECT = 1\n",
        "LOG_INTERVALS = 1 # 200\n",
        "TEST_INTERVALS = 2 # 1000\n",
        "MEMORY_LENGTH = OBS_SPACE * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4DpIfIPH0Ch"
      },
      "source": [
        "# Financial Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "s64pmt9mH0Cj",
        "outputId": "39e9380d-7462-4491-e6a9-99f50304d22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TSLA => min_date: 2017-01-03 00:00:00, max_date: 2019-12-30 00:00:00, kurt:-0.56, skewness:-0.28, outliers_count:0,  nan_count: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Open       High        Low      Close  Adj Close     Volume\n",
              "Date                                                                        \n",
              "2017-01-03  14.324000  14.688667  14.064000  14.466000  14.466000   88849500\n",
              "2017-01-04  14.316667  15.200000  14.287333  15.132667  15.132667  168202500\n",
              "2017-01-05  15.094667  15.165333  14.796667  15.116667  15.116667   88675500\n",
              "2017-01-06  15.128667  15.354000  15.030000  15.267333  15.267333   82918500\n",
              "2017-01-09  15.264667  15.461333  15.200000  15.418667  15.418667   59692500\n",
              "...               ...        ...        ...        ...        ...        ...\n",
              "2019-12-23  27.452000  28.134001  27.333332  27.948000  27.948000  199794000\n",
              "2019-12-24  27.890667  28.364668  27.512667  28.350000  28.350000  120820500\n",
              "2019-12-26  28.527332  28.898666  28.423332  28.729334  28.729334  159508500\n",
              "2019-12-27  29.000000  29.020666  28.407333  28.691999  28.691999  149185500\n",
              "2019-12-30  28.586000  28.600000  27.284000  27.646667  27.646667  188796000\n",
              "\n",
              "[753 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5350fd79-30f7-4a5a-bc57-9276aac67666\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2017-01-03</th>\n",
              "      <td>14.324000</td>\n",
              "      <td>14.688667</td>\n",
              "      <td>14.064000</td>\n",
              "      <td>14.466000</td>\n",
              "      <td>14.466000</td>\n",
              "      <td>88849500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-04</th>\n",
              "      <td>14.316667</td>\n",
              "      <td>15.200000</td>\n",
              "      <td>14.287333</td>\n",
              "      <td>15.132667</td>\n",
              "      <td>15.132667</td>\n",
              "      <td>168202500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-05</th>\n",
              "      <td>15.094667</td>\n",
              "      <td>15.165333</td>\n",
              "      <td>14.796667</td>\n",
              "      <td>15.116667</td>\n",
              "      <td>15.116667</td>\n",
              "      <td>88675500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-06</th>\n",
              "      <td>15.128667</td>\n",
              "      <td>15.354000</td>\n",
              "      <td>15.030000</td>\n",
              "      <td>15.267333</td>\n",
              "      <td>15.267333</td>\n",
              "      <td>82918500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-01-09</th>\n",
              "      <td>15.264667</td>\n",
              "      <td>15.461333</td>\n",
              "      <td>15.200000</td>\n",
              "      <td>15.418667</td>\n",
              "      <td>15.418667</td>\n",
              "      <td>59692500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-23</th>\n",
              "      <td>27.452000</td>\n",
              "      <td>28.134001</td>\n",
              "      <td>27.333332</td>\n",
              "      <td>27.948000</td>\n",
              "      <td>27.948000</td>\n",
              "      <td>199794000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-24</th>\n",
              "      <td>27.890667</td>\n",
              "      <td>28.364668</td>\n",
              "      <td>27.512667</td>\n",
              "      <td>28.350000</td>\n",
              "      <td>28.350000</td>\n",
              "      <td>120820500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-26</th>\n",
              "      <td>28.527332</td>\n",
              "      <td>28.898666</td>\n",
              "      <td>28.423332</td>\n",
              "      <td>28.729334</td>\n",
              "      <td>28.729334</td>\n",
              "      <td>159508500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-27</th>\n",
              "      <td>29.000000</td>\n",
              "      <td>29.020666</td>\n",
              "      <td>28.407333</td>\n",
              "      <td>28.691999</td>\n",
              "      <td>28.691999</td>\n",
              "      <td>149185500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-12-30</th>\n",
              "      <td>28.586000</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>27.284000</td>\n",
              "      <td>27.646667</td>\n",
              "      <td>27.646667</td>\n",
              "      <td>188796000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>753 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5350fd79-30f7-4a5a-bc57-9276aac67666')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5350fd79-30f7-4a5a-bc57-9276aac67666 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5350fd79-30f7-4a5a-bc57-9276aac67666');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-34f0bf2a-6815-42b2-adec-04e8f0193118\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34f0bf2a-6815-42b2-adec-04e8f0193118')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-34f0bf2a-6815-42b2-adec-04e8f0193118 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"tickers[TARGET]\",\n  \"rows\": 753,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2017-01-03 00:00:00\",\n        \"max\": \"2019-12-30 00:00:00\",\n        \"num_unique_values\": 753,\n        \"samples\": [\n          \"2019-11-06 00:00:00\",\n          \"2019-08-06 00:00:00\",\n          \"2018-06-25 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0998823778838096,\n        \"min\": 12.073332786560059,\n        \"max\": 29.0,\n        \"num_unique_values\": 711,\n        \"samples\": [\n          20.118667602539062,\n          21.391332626342773,\n          20.06800079345703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1384437712983404,\n        \"min\": 12.445332527160645,\n        \"max\": 29.020666122436523,\n        \"num_unique_values\": 708,\n        \"samples\": [\n          25.796667098999023,\n          21.05466651916504,\n          19.631332397460938\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.052082343134819,\n        \"min\": 11.799332618713379,\n        \"max\": 28.42333221435547,\n        \"num_unique_values\": 721,\n        \"samples\": [\n          23.399999618530273,\n          15.915332794189453,\n          20.600000381469727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0939495816459504,\n        \"min\": 11.9313325881958,\n        \"max\": 28.729333877563477,\n        \"num_unique_values\": 735,\n        \"samples\": [\n          17.89466667175293,\n          18.492666244506836,\n          21.487333297729492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0939495816459504,\n        \"min\": 11.9313325881958,\n        \"max\": 28.729333877563477,\n        \"num_unique_values\": 735,\n        \"samples\": [\n          17.89466667175293,\n          18.492666244506836,\n          21.487333297729492\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 66969490,\n        \"min\": 32800500,\n        \"max\": 504745500,\n        \"num_unique_values\": 751,\n        \"samples\": [\n          108093000,\n          89928000,\n          84378000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "def get_tickerdata(tickers_symbols, start=START_DATE, end=END_DATE, interval=INTERVAL, datadir=DATA_DIR):\n",
        "    tickers = {}\n",
        "    earliest_end= datetime.strptime(end,'%Y-%m-%d')\n",
        "    latest_start = datetime.strptime(start,'%Y-%m-%d')\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "    for symbol in tickers_symbols:\n",
        "        cached_file_path = f\"{datadir}/{symbol}-{start}-{end}-{interval}.csv\"\n",
        "\n",
        "        try:\n",
        "            if os.path.exists(cached_file_path):\n",
        "                df = pd.read_parquet(cached_file_path)\n",
        "                df.index = pd.to_datetime(df.index)\n",
        "                assert len(df) > 0\n",
        "            else:\n",
        "                df = yf.download(\n",
        "                    symbol,\n",
        "                    start=START_DATE,\n",
        "                    end=END_DATE,\n",
        "                    progress=False,\n",
        "                    interval=INTERVAL,\n",
        "                )\n",
        "                assert len(df) > 0\n",
        "                df.to_parquet(cached_file_path, index=True, compression=\"snappy\")\n",
        "            min_date = df.index.min()\n",
        "            max_date = df.index.max()\n",
        "            nan_count = df[\"Close\"].isnull().sum()\n",
        "            skewness = round(skew(df[\"Close\"].dropna()), 2)\n",
        "            kurt = round(kurtosis(df[\"Close\"].dropna()), 2)\n",
        "            outliers_count = (df[\"Close\"] > df[\"Close\"].mean() + (3 * df[\"Close\"].std())).sum()\n",
        "            print(\n",
        "                f\"{symbol} => min_date: {min_date}, max_date: {max_date}, kurt:{kurt}, skewness:{skewness}, outliers_count:{outliers_count},  nan_count: {nan_count}\"\n",
        "            )\n",
        "            tickers[symbol] = df\n",
        "\n",
        "            if min_date > latest_start:\n",
        "                latest_start = min_date\n",
        "            if max_date < earliest_end:\n",
        "                earliest_end = max_date\n",
        "        except Exception as e:\n",
        "            print(f\"Error with {symbol}: {e}\")\n",
        "\n",
        "    return tickers, latest_start, earliest_end\n",
        "\n",
        "tickers, latest_start, earliest_end = get_tickerdata(TICKER_SYMBOLS)\n",
        "tickers[TARGET]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lke4koO5H0Cl"
      },
      "source": [
        "# Trading Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXLhk-CKH0Co",
        "outputId": "c2695606-19c3-40f0-9a7a-2e21c4e5b394"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TimeStep Specs: TimeStep(\n",
            "{'step_type': ArraySpec(shape=(), dtype=dtype('int32'), name='step_type'),\n",
            " 'reward': ArraySpec(shape=(), dtype=dtype('float32'), name='reward'),\n",
            " 'discount': BoundedArraySpec(shape=(), dtype=dtype('float32'), name='discount', minimum=0.0, maximum=1.0),\n",
            " 'observation': BoundedArraySpec(shape=(5,), dtype=dtype('float32'), name='observation', minimum=-3.4028234663852886e+38, maximum=3.4028234663852886e+38)})\n",
            "Action Specs: BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=2)\n",
            "Reward Specs: ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n",
            "Time step: TimeStep(\n",
            "{'step_type': array(0, dtype=int32),\n",
            " 'reward': array(0., dtype=float32),\n",
            " 'discount': array(1., dtype=float32),\n",
            " 'observation': array([1.4466000e+01, 1.4688667e+01, 1.4064000e+01, 1.4324000e+01,\n",
            "       8.8849504e+07], dtype=float32)})\n",
            "Next time step: TimeStep(\n",
            "{'step_type': array(1, dtype=int32),\n",
            " 'reward': array(0., dtype=float32),\n",
            " 'discount': array(1., dtype=float32),\n",
            " 'observation': array([1.5132667e+01, 1.5200000e+01, 1.4287333e+01, 1.4316667e+01,\n",
            "       1.6820250e+08], dtype=float32)})\n"
          ]
        }
      ],
      "source": [
        "class TradingEnv(py_environment.PyEnvironment):\n",
        "    \"\"\"\n",
        "    A custom trading environment for reinforcement learning, compatible with tf_agents.\n",
        "\n",
        "    This environment simulates a simple trading scenario where an agent can take one of three actions:\n",
        "    - Long (buy), Short (sell), or Hold a financial instrument, aiming to maximize profit through trading decisions.\n",
        "\n",
        "    Parameters:\n",
        "    - data: DataFrame containing the stock market data.\n",
        "    - data_dim: Dimension of the data to be used for each observation.\n",
        "    - money: Initial capital to start trading.\n",
        "    - stateLength: Number of past observations to consider for the state.\n",
        "    - transactionCosts: Costs associated with trading actions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, features, money, stateLength, transactionCosts):\n",
        "        super(TradingEnv, self).__init__()\n",
        "        # self.data = self.preprocess_data(data)\n",
        "        self.data = data\n",
        "        self.features = features\n",
        "        self.data_dim = len(self.features)\n",
        "        self.min_balance = -money//4\n",
        "        self.initial_balance = money\n",
        "        self.state_length = stateLength\n",
        "        self.transaction_cost = transactionCosts\n",
        "        self._episode_ended = False\n",
        "\n",
        "        self._batch_size = 1\n",
        "        self._action_spec = array_spec.BoundedArraySpec(shape=(), dtype=np.int32, minimum=ACT_SHORT, maximum=ACT_LONG, name='action')\n",
        "        self._observation_spec = array_spec.BoundedArraySpec(shape=(self.data_dim,), dtype=np.float32, name='observation')\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    @property\n",
        "    def batched(self):\n",
        "        return False #True\n",
        "\n",
        "    @property\n",
        "    def batch_size(self):\n",
        "        return None #self._batch_size\n",
        "\n",
        "    @batch_size.setter\n",
        "    def batch_size(self, size):\n",
        "        self._batch_size = size\n",
        "\n",
        "    def preprocess_data(self, df):\n",
        "        log_returns = np.log(df / df.shift(1))\n",
        "        normalized_data = (log_returns - log_returns.mean()) / log_returns.std()\n",
        "        normalized_data.dropna(inplace=True)\n",
        "        return normalized_data\n",
        "\n",
        "    def action_spec(self):\n",
        "        \"\"\"Provides the specification of the action space.\"\"\"\n",
        "        return self._action_spec\n",
        "\n",
        "    def observation_spec(self):\n",
        "        \"\"\"Provides the specification of the observation space.\"\"\"\n",
        "        return self._observation_spec\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"Resets the environment state and prepares for a new episode.\"\"\"\n",
        "        self.balance = self.initial_balance\n",
        "        self.position = 0\n",
        "        self.total_shares = 0\n",
        "        self.current_step = self.state_length\n",
        "        self._episode_ended = False\n",
        "        initial_observation = self._next_observation()\n",
        "        return ts.restart(initial_observation)\n",
        "\n",
        "    def _next_observation(self):\n",
        "        \"\"\"Generates the next observation based on the current step.\"\"\"\n",
        "        obs = self.data[self.features].iloc[self.current_step-self.state_length:self.current_step]\n",
        "        obs = obs.values[0]\n",
        "        obs = obs.flatten().astype(np.float32)\n",
        "        return obs\n",
        "\n",
        "    def _step(self, action):\n",
        "        \"\"\"Executes a trading action and returns the new state of the environment.\"\"\"\n",
        "        if self._episode_ended:\n",
        "            return self.reset()\n",
        "\n",
        "        current_price = self.data.iloc[self.current_step]['Close']\n",
        "        self.current_step += 1\n",
        "        reward = 0\n",
        "\n",
        "        if action == ACT_SHORT or action == ACT_LONG:\n",
        "            if self.total_shares > 0:\n",
        "                self.balance += self.total_shares * current_price * (1 - self.transaction_cost)\n",
        "                reward = self.balance - self.initial_balance\n",
        "                self.total_shares = 0\n",
        "            if action == ACT_LONG:\n",
        "                self.position = 1\n",
        "                self.total_shares = self.balance // (current_price * (1 + self.transaction_cost))\n",
        "                self.balance -= self.total_shares * current_price * (1 + self.transaction_cost)\n",
        "            elif action == ACT_SHORT:\n",
        "                self.position = -1\n",
        "\n",
        "        if self.balance < self.min_balance:\n",
        "            # bankrupt\n",
        "            done = True\n",
        "            reward = -1\n",
        "        else:\n",
        "            done = self.current_step >= len(self.data)\n",
        "        reward = np.clip(reward, -1, 1)\n",
        "        if done:\n",
        "            self._episode_ended = True\n",
        "            return ts.termination(self._next_observation(), reward)\n",
        "        else:\n",
        "            return ts.transition(self._next_observation(), reward)\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        print(f'Step: {self.current_step}, Balance: {self.balance}')\n",
        "\n",
        "stock= tickers[TARGET]\n",
        "train_data = stock[stock.index < pd.to_datetime(SPLIT_DATE)].copy()\n",
        "test_data = stock[stock.index >= pd.to_datetime(SPLIT_DATE)].copy()\n",
        "\n",
        "train_env = TradingEnv(train_data, FEATURES, CAPITAL, STATE_LEN, FEES)\n",
        "utils.validate_py_environment(train_env, episodes=EPISODES)\n",
        "test_env = TradingEnv(test_data, FEATURES, CAPITAL, STATE_LEN, FEES)\n",
        "utils.validate_py_environment(train_env, episodes=EPISODES//4)\n",
        "\n",
        "print(f\"TimeStep Specs: {train_env.time_step_spec()}\")\n",
        "print(f\"Action Specs: {train_env.action_spec()}\")\n",
        "print(f\"Reward Specs: {train_env.time_step_spec().reward}\")\n",
        "\n",
        "time_step = train_env.reset()\n",
        "print(f'Time step: {time_step}')\n",
        "action = np.array(ACT_HOLD, dtype=np.int32)\n",
        "next_time_step = train_env.step(action)\n",
        "print(f'Next time step: {next_time_step}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcb7hq6yH0Cq"
      },
      "source": [
        "# Deep Q-Network Architecure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AIE_vPrH0Cr"
      },
      "source": [
        "## Architecture\n",
        "\n",
        "2 models:\n",
        "- Policy Model: This is the primary model that the agent uses to make decisions or select actions based on the current state of the environment. The policy model is actively trained and updated throughout the training process based on the agent's experiences. In real-life applications, after the training phase is complete, the policy model is what gets deployed to make decisions or take actions in the given environment.\n",
        "- Target Model: The target model is used exclusively during the training phase to provide a stable target for the temporal difference (TD) error calculation, which is crucial for the stability of the Q-learning updates. The target model's weights are periodically synchronized with the policy model's weights but at a much slower rate. This delayed update helps to stabilize the learning process by making the target for the policy updates more consistent across training batches. The target model itself is not used for decision-making or action selection outside of the training context.\n",
        "\n",
        "Some notes on this 2 model arch:\n",
        "- Stability/Reducing Temporal Correlations: The agent learns a policy that maps states to actions by using a Q-function. This Q-function estimates the rewards by taking a certain action in a given state. The learning process continuously updates the Q-values based on new experiences. If the Q-function is constantly changing—as it would be when updates are made based on estimates from the same function—it can lead to unstable training dynamics. The estimates can become overly optimistic, and the learning process can diverge.\n",
        "- Target: The target network is a stable baseline for the policy network to compare against. While the policy network is frequently updated to reflect the latest learning, the target network's weights are updated less frequently. This slower update rate provides a fixed target for the policy network to aim for over multiple iterations, making the learning process more stable.\n",
        "\n",
        "In practice, the policy network is responsible for selecting actions during training and gameplay. Its weights are regularly updated to reflect the agent's learning. The target network, on the other hand, is used to generate the Q-value targets for the updates of the policy network. Every few steps, the weights from the policy network are copied to the target network, ensuring the target for the updates remains relatively stable but still gradually adapts to the improved policy. The policy model is used both during training (for learning and decision-making) and after training (for decision-making in the deployment environment).\n",
        "\n",
        "The target model is used during the training process only, to calculate stable target values for updating the policy model.\n",
        "After training is complete and the model is deployed in a real-world application, only the policy model is used to make decisions or take actions based on the learned policy. The target model's role ends with the completion of the training phase, as its primary purpose is to aid in the convergence and stability of the training process itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q49V1zseH0Cs"
      },
      "source": [
        "## DRL Flow\n",
        "\n",
        "- Initialization: init policy network and the target network with the same architecture but separate parameters.\n",
        "- Data Preparation: Normalize input data using calculated coefficients to ensure consistency in scale.\n",
        "- Learning Process:\n",
        "    -At each training step, observe the current market state and process it through normalization.\n",
        "    - Select an action using the epsilon-greedy policy (a balance between exploration and exploitation) based on the current state.\n",
        "    - Execute the selected action in the simulated trading environment, observe the next state, and receive a reward based on the action's outcome.\n",
        "    - Store the experience (current state, action, reward, next state) in the replay memory.\n",
        "    - Sample a random batch of past experiences from the replay memory for learning to reduce correlation between consecutive learning steps.\n",
        "    - Use the policy network to predict Q-values for the current states and the target network to calculate the target Q-values for the next states.\n",
        "    - Update the policy network by minimizing the difference between its Q-value predictions and the target Q-values using backpropagation.\n",
        "    - Every few steps, update the target network's parameters with the policy network's parameters to gradually adapt the learning target.\n",
        "- Evaluation and Adjustment: Periodically test the trained policy network on a separate validation set or environment to evaluate performance.\n",
        "    -Repeat the learning and evaluation process for many episodes until the policy network stabilizes and performs satisfactorily.\n",
        "- Application Phase\n",
        "    - Model Deployment: Deploy the trained policy network in a real-world environment or a simulation that closely mimics real trading conditions.\n",
        "    - Real-time Operation: Observe the current market state and process it (normalization, etc.) as done during training.\n",
        "    - Use the trained policy network to select the action that maximizes expected rewards based on the current market state, leaning towards exploitation of the learned policy over exploration. Execute the selected action in the market (buy, sell, hold).\n",
        "- Continuous Learning:\n",
        "    - Repeat the learning process with new market data and experiences, possibly in a less frequent, offline manner.\n",
        "    - Update the policy and target networks as new data becomes available and as the market evolves to maintain or improve performance over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y5vgYpxH0Cs",
        "outputId": "e071dc42-98f8-4037-aa74-6c12472a0f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  0\n",
            "<tf_agents.policies.greedy_policy.GreedyPolicy object at 0x799208fc5f00>\n",
            "<tf_agents.policies.epsilon_greedy_policy.EpsilonGreedyPolicy object at 0x799208fc5db0>\n"
          ]
        }
      ],
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "def create_q_network(env, fc_layer_params = (100, 50)):\n",
        "    env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "    action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
        "    num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
        "\n",
        "    def _dense_layer(num_units):\n",
        "        return tf.keras.layers.Dense(\n",
        "            num_units,\n",
        "            activation=tf.keras.activations.relu,\n",
        "            kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
        "                scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
        "\n",
        "    dense_layers = [_dense_layer(num_units) for num_units in fc_layer_params]\n",
        "    q_values_layer = tf.keras.layers.Dense(\n",
        "        num_actions,\n",
        "        activation=None,\n",
        "        kernel_initializer=tf.keras.initializers.RandomUniform(\n",
        "            minval=-0.03, maxval=0.03),\n",
        "        bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
        "    q_net = sequential.Sequential(dense_layers + [q_values_layer])\n",
        "\n",
        "    return q_net\n",
        "\n",
        "def create_agent(q_net, env, optimizer = tf.keras.optimizers.Adam(learning_rate=LEARN_RATE)):\n",
        "    env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "    train_step_counter = tf.Variable(0)\n",
        "    agent = dqn_agent.DqnAgent(\n",
        "        env.time_step_spec(),\n",
        "        env.action_spec(),\n",
        "        q_network=q_net,\n",
        "        optimizer=optimizer,\n",
        "        epsilon_greedy = 1.,\n",
        "        td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "        train_step_counter=train_step_counter)\n",
        "\n",
        "    agent.initialize()\n",
        "    print(agent.policy)\n",
        "    print(agent.collect_policy)\n",
        "    return agent\n",
        "\n",
        "q_net = create_q_network(train_env)\n",
        "agent = create_agent(q_net, train_env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXZ_bo04H0Ct"
      },
      "source": [
        "# Trading Operations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7DmbtWugH0Ct",
        "outputId": "e99cc1a1-362d-40f4-9f7b-944d9febdace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trajectory(\n",
            "{'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
            " 'observation': BoundedTensorSpec(shape=(5,), dtype=tf.float32, name='observation', minimum=array(-3.4028235e+38, dtype=float32), maximum=array(3.4028235e+38, dtype=float32)),\n",
            " 'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(2, dtype=int32)),\n",
            " 'policy_info': (),\n",
            " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
            " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
            " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32))})\n",
            "('step_type', 'observation', 'action', 'policy_info', 'next_step_type', 'reward', 'discount')\n",
            "TimeStep(\n",
            "{'step_type': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>,\n",
            " 'reward': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
            " 'discount': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>,\n",
            " 'observation': <tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
            "array([[1.4466000e+01, 1.4688667e+01, 1.4064000e+01, 1.4324000e+01,\n",
            "        8.8849504e+07]], dtype=float32)>})\n",
            "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([1], dtype=int32)>, state=(), info=())\n",
            "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7992132cc520>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Loop:   0%|          | 0/10 [00:00<?, ?it/s]WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
            "Training Loop:  10%|█         | 1/10 [00:02<00:19,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 1: loss = 20876026183680.0\n",
            "step = 2: loss = 5131141644288.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Loop:  20%|██        | 2/10 [00:13<01:00,  7.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 2: Average Return = 0.0\n",
            "step = 3: loss = 2030732312576.0\n",
            "step = 4: loss = 3346116116480.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Loop:  40%|████      | 4/10 [00:24<00:38,  6.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 4: Average Return = 0.0\n",
            "step = 5: loss = 3900519219200.0\n",
            "step = 6: loss = 2406473793536.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Loop:  60%|██████    | 6/10 [00:36<00:24,  6.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 6: Average Return = 0.0\n",
            "step = 7: loss = 2390858924032.0\n",
            "step = 8: loss = 3822194524160.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Loop:  80%|████████  | 8/10 [00:47<00:11,  5.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 8: Average Return = 0.0\n",
            "step = 9: loss = 5216951861248.0\n",
            "step = 10: loss = 11412348862464.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Loop: 100%|██████████| 10/10 [00:58<00:00,  5.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 10: Average Return = 0.0\n",
            "\n",
            "Training completed. Mean Reward: -3322.6895, Mean Loss: 11412348862464.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./models/dqn_trained.h5-1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGyCAYAAAA4UbqlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQKklEQVR4nO3de1xUZf4H8M8MMAMIDHIHg4Aw8ZYgyE1/pslKm7vFamZmpWZlhpZimZaXbl7SNPLSkmVa283cNrfM3AjNVgQ1hFJTk5BF5ZYiM6Bynef3h83JCVRGZzjMzOf9ep3X7pzzzOF75tev+ew533kehRBCgIiIiIjMRil3AURERES2hgGLiIiIyMwYsIiIiIjMjAGLiIiIyMwYsIiIiIjMjAGLiIiIyMwYsIiIiIjMjAGLiIiIyMwYsIiIiIjMzFHuAuyVXq9HWVkZ3N3doVAo5C6HiIiI2kEIgdraWgQFBUGpvPx9Kgas67BmzRosW7YMFRUV6NevH1atWoW4uLh2vbesrAzBwcEWrpCIiIgs4cSJE7jhhhsue5wB6xpt3LgR6enpyMzMRHx8PDIyMpCSkoKjR4/Cz8/vqu93d3cHcPH/QB4eHpYul4iIiMxAp9MhODhY+h6/HAUXe7428fHxGDBgAFavXg3g4iO/4OBgTJs2DbNnz77q+3U6HTQaDbRaLQMWERGRlWjv9zfvYF2DxsZG5OfnY86cOdI+pVKJ5ORk5ObmtvmehoYGNDQ0SK91Op3F6yTL+bW2Ae/uLsH5xha5SyEiosu4Lz4EEX5usvxtBqxrcPr0abS0tMDf399ov7+/P44cOdLmexYvXowXXnihI8qjDrBmRxE27C6RuwwiIrqCIT18GbBs3Zw5c5Ceni69NjzDJeu0q+g0AODOfkHo1tVF5mqIiKgtwV6usv1tBqxr4OPjAwcHB1RWVhrtr6ysREBAQJvvUavVUKvVHVEeWVilrh5FVXVQKIAX7+oNT1eV3CUREVEnw4lGr4FKpUJMTAyys7OlfXq9HtnZ2UhMTJSxMuoIub+cAQD0DvJguCIiojbxDtY1Sk9Px/jx4xEbG4u4uDhkZGTg3LlzmDhxotylkYXl/PZ4cOBNPjJXQkREnRUD1jUaM2YMfv31V8yfPx8VFRWIiorCtm3bWjW+k20RQmD3b3ewEm/ylrkaIiLqrBiwrsPUqVMxdepUucugDnSi+gJO1VyAo1KBAaFecpdDRESdFHuwiEyQ88vFx4PRIZ7ooub/PiEiorYxYBGZ4PfHg+y/IiKiy2PAImonIQRyf7uDlcT+KyIiugIGLKJ2+rmyDqfrGuHspER0iKfc5RARUSfGgEXUTrt/u3s1INQLakcHmashIqLOjAGLqJ1yii72XyWx/4qIiK6CAYuoHZpb9NhTbAhY7L8iIqIrY8AiaodDZTrUNjTD3dkRfbpp5C6HiIg6OQYsonYwzH+VEO4NB6VC5mqIiKizY8AiagfDAs98PEhERO3BgEV0FQ3NLdhXUg2ADe5ERNQ+DFhEV1FQWoP6Jj183FS42d9N7nKIiMgKMGARXcWly+MoFOy/IiKiq2PAIroKw/I4A9l/RURE7cSARXQF5xqaUVBaA4D9V0RE1H4MWERXsK+kGs16gW6eLgj2cpG7HCIishIMWERXYOi/Ghjhzf4rIiJqNwYsoiswLPDMx4NERGQKBiyiy6g534hDZToAQCIb3ImIyAQMWESXkVd8BkIAEX5u8PdwlrscIiKyIgxYRJexm8vjEBHRNWLAIrqM3wMW+6+IiMg0DFhEbajU1aOoqg4KBZAQ7iV3OUREZGUYsIjakPvb3aveQR7wdFXJXA0REVkbBiyiNuQUGZbH4eNBIiIyHQMW0R8IIS5Z4JkN7kREZDoGLKI/OFF9AadqLsBRqcCAUPZfERGR6RiwiP4g57fZ26NDPNFF7ShzNUREZI0YsIj+4PfHg+y/IiKia8OARXQJIQRypfUH2X9FRETXhgGL6BI/V9bhdF0jnJ2UiA7xlLscIiKyUgxYRJfY/dvdqwGhXlA7OshcDRERWSsGLKJLcHkcIiIyB5sJWCUlJZg0aRLCwsLg4uKCm266CQsWLEBjY6PRGIVC0WrLy8szOtemTZsQGRkJZ2dn9O3bF1u3bjU6LoTA/PnzERgYCBcXFyQnJ+PYsWMdcp1kOc0teuQVc4FnIiK6fjYTsI4cOQK9Xo8333wThw4dwmuvvYbMzEw8++yzrcZ+8803KC8vl7aYmBjp2O7duzF27FhMmjQJBQUFSE1NRWpqKg4ePCiNWbp0KVauXInMzEzs2bMHXbp0QUpKCurr6zvkWskyDpXpUFvfDHdnR/TpppG7HCIismIKIYSQuwhLWbZsGf7+97+juLgYwMU7WGFhYSgoKEBUVFSb7xkzZgzOnTuHLVu2SPsSEhIQFRWFzMxMCCEQFBSEmTNn4qmnngIAaLVa+Pv7Y8OGDbj33nvbVZtOp4NGo4FWq4WHh8f1XSiZxRvfFmHptqP4Uy9/vPVgrNzlEBFRJ9Te72+buYPVFq1WCy+v1jNx33nnnfDz88OgQYPw+eefGx3Lzc1FcnKy0b6UlBTk5uYCAI4fP46KigqjMRqNBvHx8dKYtjQ0NECn0xlt1Lnk/sLHg0REZB42G7CKioqwatUqTJ48Wdrn5uaG5cuXY9OmTfjyyy8xaNAgpKamGoWsiooK+Pv7G53L398fFRUV0nHDvsuNacvixYuh0WikLTg4+LqvkcynobkF+0qqAbDBnYiIrl+nD1izZ89uszH90u3IkSNG7zl16hRuv/12jB49Go888oi038fHB+np6YiPj8eAAQOwZMkS3H///Vi2bJnFr2POnDnQarXSduLECYv/TWq/gtIa1Dfp4eOmws3+bnKXQ0REVq7TL7Q2c+ZMTJgw4YpjwsPDpf9eVlaGoUOHIikpCWvXrr3q+ePj45GVlSW9DggIQGVlpdGYyspKBAQESMcN+wIDA43GXK6vCwDUajXUavVV6yF5XLo8jkKhkLkaIiKydp0+YPn6+sLX17ddY0+dOoWhQ4ciJiYG69evh1J59Rt0hYWFRkEpMTER2dnZmD59urQvKysLiYmJAICwsDAEBAQgOztbClQ6nQ579uzBlClT2n9h1KkYlscZyP4rIiIyg04fsNrr1KlTGDJkCG688Ua8+uqr+PXXX6VjhrtO7777LlQqFaKjowEA//rXv/DOO+/g7bfflsY++eSTuPXWW7F8+XKMGDECH3/8Mb7//nvpbphCocD06dPx8ssvo3v37ggLC8O8efMQFBSE1NTUjrtgMptzDc0oKK0BwP4rIiIyD5sJWFlZWSgqKkJRURFuuOEGo2OXzkTx0ksv4X//+x8cHR0RGRmJjRs34u6775aOJyUl4cMPP8TcuXPx7LPPonv37ti8eTP69OkjjZk1axbOnTuHRx99FDU1NRg0aBC2bdsGZ2dny18omd2+kmo06wW6ebog2MtF7nKIiMgG2PQ8WJ0Z58HqPBZtPYy13xXjntgbsPTufnKXQ0REnRjnwSJqJ8MCz3w8SERE5sKARXat5nwjDpVdnPQ1kQ3uRERkJgxYZNfyis9ACCDCzw3+HuyhIyIi82DAIru2m8vjEBGRBTBgkV37PWCx/4qIiMyHAYvsVqWuHkVVdVAogITw1ouCExERXSsGLLJbub/dveod5AFPV5XM1RARkS1hwCK7tVtaHoePB4mIyLwYsMguCSGQU2RY4JkN7kREZF4MWGSXTlRfwKmaC3BUKjAglP1XRERkXgxYZJdyfns8GB3iiS5qm1mSk4iIOgkGLLJLhukZEtl/RUREFsCARXZHCIFcaf1B9l8REZH5MWCR3fm5sg6n6xrh7KREdIin3OUQEZENYsAiu2OYnmFAqBfUjg4yV0NERLaIAYvsDpfHISIiS2PAIrvS3KJHXjEXeCYiIstiwCK7cqhMh9r6Zrg7O6JPN43c5RARkY1iwCK7Ypj/KiHcGw5KhczVEBGRrWLAIruS+wsfDxIRkeUxYJHdaGhuwb6SagBscCciIstiwCK7UVBag/omPXzcVLjZ303ucoiIyIYxYJHduHR5HIWC/VdERGQ5DFhkNwzL4wxk/xUREVkYAxbZhXMNzSgorQHA/isiIrI8BiyyC/tKqtGsF+jm6YJgLxe5yyEiIhvHgEV2wTA9w8AIb/ZfERGRxTFgkV0wTDDKx4NERNQRGLDI5tWcb8ShMh0AIJEN7kRE1AEYsMjm5RWfgRBAhJ8b/D2c5S6HiIjsAAMW2bzdXB6HiIg6GAMW2bzfAxb7r4iIqGPYVMAKDQ2FQqEw2pYsWWI05scff8T//d//wdnZGcHBwVi6dGmr82zatAmRkZFwdnZG3759sXXrVqPjQgjMnz8fgYGBcHFxQXJyMo4dO2bRa6NrU6mrR1FVHRQKICHcS+5yiIjITthUwAKAF198EeXl5dI2bdo06ZhOp8Pw4cNx4403Ij8/H8uWLcPzzz+PtWvXSmN2796NsWPHYtKkSSgoKEBqaipSU1Nx8OBBaczSpUuxcuVKZGZmYs+ePejSpQtSUlJQX1/foddKV2eYnqF3kAc8XVUyV0NERPbC5gKWu7s7AgICpK1Lly7SsQ8++ACNjY1455130Lt3b9x777144oknsGLFCmnM66+/jttvvx1PP/00evbsiZdeegn9+/fH6tWrAVy8e5WRkYG5c+firrvuwi233IL33nsPZWVl2Lx5c0dfLl3Fbml5HD4eJCKijmNzAWvJkiXw9vZGdHQ0li1bhubmZulYbm4uBg8eDJXq9zsZKSkpOHr0KM6ePSuNSU5ONjpnSkoKcnNzAQDHjx9HRUWF0RiNRoP4+HhpDHUOQgjkFBkWeGaDOxERdRxHuQswpyeeeAL9+/eHl5cXdu/ejTlz5qC8vFy6Q1VRUYGwsDCj9/j7+0vHunbtioqKCmnfpWMqKiqkcZe+r60xbWloaEBDQ4P0WqfTXeNVUnudqL6AUzUX4KhUYEAo+6+IiKjjdPo7WLNnz27VuP7H7ciRIwCA9PR0DBkyBLfccgsee+wxLF++HKtWrTIKNnJZvHgxNBqNtAUHB8tdks0zzN4eHeKJLmqb+t8SRETUyXX6b52ZM2diwoQJVxwTHh7e5v74+Hg0NzejpKQEPXr0QEBAACorK43GGF4HBARI/9nWmEuPG/YFBgYajYmKirpsjXPmzEF6err0WqfTMWRZmGF6hkT2XxERUQfr9AHL19cXvr6+1/TewsJCKJVK+Pn5AQASExPx3HPPoampCU5OTgCArKws9OjRA127dpXGZGdnY/r06dJ5srKykJiYCAAICwtDQEAAsrOzpUCl0+mwZ88eTJky5bK1qNVqqNXqa7oOMp0QArlSgzv7r4iIqGN1+keE7ZWbm4uMjAz88MMPKC4uxgcffIAZM2bg/vvvl8LTfffdB5VKhUmTJuHQoUPYuHEjXn/9daM7S08++SS2bduG5cuX48iRI3j++efx/fffY+rUqQAAhUKB6dOn4+WXX8bnn3+OAwcO4MEHH0RQUBBSU1PluHRqw8+VdThd1whnJyWiQjzlLoeIiOxMp7+D1V5qtRoff/wxnn/+eTQ0NCAsLAwzZswwCk8ajQZff/010tLSEBMTAx8fH8yfPx+PPvqoNCYpKQkffvgh5s6di2effRbdu3fH5s2b0adPH2nMrFmzcO7cOTz66KOoqanBoEGDsG3bNjg7c527zsIwPcOAUC+oHR1kroaIiOyNQggh5C7CHul0Omg0Gmi1Wnh4eMhdjs155L3vkfVTJZ65PRJThtwkdzlERGQj2vv9bTOPCIkMmlv0yCvmAs9ERCQfBiyyOYfKdKitb4a7syP6dNPIXQ4REdkhBiyyOYbpGRLCveGgVMhcDRER2SMGLLI5hgZ3Ph4kIiK5MGCRTWlobsG+kmoAQBInGCUiIpkwYJFNKSitQX2THj5uKtzs7yZ3OUREZKcYsMimXLo8jkLB/isiIpIHAxbZFC6PQ0REnQEDFtmMcw3NKCitAcD+KyIikhcDFtmMfSXVaNYLdPN0QbCXi9zlEBGRHWPAIpuR+1v/1cAIb/ZfERGRrBiwyGbkSPNf8fEgERHJiwGLbELN+UYcKtMBABLZ4E5ERDJjwCKbkFd8BkIAEX5u8PdwlrscIiKycwxYZBMM819xeRwiIuoMGLDIJvwesNh/RURE8mPAIqtXqatHUVUdFAogIdxL7nKIiIgYsMj6GaZn6B3kAU9XlczVEBERMWCRDdgtLY/Dx4NERNQ5MGCRVRNCIKfIsMAzG9yJiKhzYMAiq3ai+gJO1VyAo1KBAaHsvyIios6BAYusmuHxYHSIJ7qoHWWuhoiI6CIGLLJqOb8YHg+y/4qIiDoPBiyyWkII5EoN7uy/IiKizoMBi6zWz5V1OF3XCGcnJaJCPOUuh4iISMKARVbL0H81INQLakcHmashIiL6HQMWWS0uj0NERJ0VAxZZpeYWPfKKucAzERF1TgxYZJUOlelQW98Md2dH9OmmkbscIiIiIwxYZJUMjwcTwr3hoFTIXA0REZExBiyySoYGdz4eJCKizogBi6xOQ3ML9pVUA2CDOxERdU4MWGR1CkprUN+kh4+bCjf7u8ldDhERUSs2E7C+/fZbKBSKNrd9+/YBAEpKSto8npeXZ3SuTZs2ITIyEs7Ozujbty+2bt1qdFwIgfnz5yMwMBAuLi5ITk7GsWPHOuxa7d3uS5bHUSjYf0VERJ2PzQSspKQklJeXG20PP/wwwsLCEBsbazT2m2++MRoXExMjHdu9ezfGjh2LSZMmoaCgAKmpqUhNTcXBgwelMUuXLsXKlSuRmZmJPXv2oEuXLkhJSUF9fX2HXa894/I4RETU2SmEEMLUNx07dgw7duxAVVUV9Hq90bH58+ebrbjr0dTUhG7dumHatGmYN28egIt3sMLCwlBQUICoqKg23zdmzBicO3cOW7ZskfYlJCQgKioKmZmZEEIgKCgIM2fOxFNPPQUA0Gq18Pf3x4YNG3Dvvfe2qz6dTgeNRgOtVgsPD4/ru1g7cq6hGf1e+BrNeoHvnh6KEG9XuUsiIiI70t7vb0dTT/zWW29hypQp8PHxQUBAgNEjGoVC0WkC1ueff44zZ85g4sSJrY7deeedqK+vx80334xZs2bhzjvvlI7l5uYiPT3daHxKSgo2b94MADh+/DgqKiqQnJwsHddoNIiPj0dubu5lA1ZDQwMaGhqk1zqd7nouz27tK6lGs16gm6cLgr1c5C6HiIioTSYHrJdffhkLFy7EM888Y4l6zGbdunVISUnBDTfcIO1zc3PD8uXLMXDgQCiVSnz66adITU3F5s2bpZBVUVEBf39/o3P5+/ujoqJCOm7Yd7kxbVm8eDFeeOEFs1ybPcv9rf9qYIQ3+6+IiKjTMrkH6+zZsxg9erQlamnT7NmzL9u8btiOHDli9J6TJ0/iP//5DyZNmmS038fHB+np6YiPj8eAAQOwZMkS3H///Vi2bJnFr2POnDnQarXSduLECYv/TVuUI81/xekZiIio8zL5Dtbo0aPx9ddf47HHHrNEPa3MnDkTEyZMuOKY8PBwo9fr16+Ht7e30aO/y4mPj0dWVpb0OiAgAJWVlUZjKisrERAQIB037AsMDDQac7m+LgBQq9VQq9VXrYcur+Z8Iw6VXXy0msgGdyIi6sRMDlgRERGYN28e8vLy0LdvXzg5ORkdf+KJJ8xWHAD4+vrC19e33eOFEFi/fj0efPDBVrW1pbCw0CgoJSYmIjs7G9OnT5f2ZWVlITExEQAQFhaGgIAAZGdnS4FKp9Nhz549mDJlSrvrJNPlFVdDCCDCzw3+Hs5yl0NERHRZJgestWvXws3NDTt37sTOnTuNjikUCrMHLFNt374dx48fx8MPP9zq2LvvvguVSoXo6GgAwL/+9S+88847ePvtt6UxTz75JG699VYsX74cI0aMwMcff4zvv/8ea9euBXDxGqdPn46XX34Z3bt3R1hYGObNm4egoCCkpqZ2yDXaKy6PQ0RE1sKkgCWEwLfffgs/Pz+4uHTOX3CtW7cOSUlJiIyMbPP4Sy+9hP/9739wdHREZGQkNm7ciLvvvls6npSUhA8//BBz587Fs88+i+7du2Pz5s3o06ePNGbWrFk4d+4cHn30UdTU1GDQoEHYtm0bnJ15V8WSDBOMsv+KiIg6O5PmwdLr9XB2dsahQ4fQvXt3S9Zl8zgPlmkqdfWIX5QNhQIomPcneLqq5C6JiIjsUHu/v036FaFSqUT37t1x5syZ6y6QyBSG6Rl6B3kwXBERUadn8jQNS5YswdNPP220dAyRpe2Wlsfh40EiIur8TG5yf/DBB3H+/Hn069cPKpWqVS9WdXW12YojAi72/uUUGRZ4ZoM7ERF1fiYHrIyMDAuUQXR5J6ov4FTNBTgqFRgQ6iV3OURERFdlcsAaP368JeoguizD48HoEE90UZv8jywREVGHM/nbqrS09IrHQ0JCrrkYorbk/GJ4PMj+KyIisg4mB6zQ0NArLrLb0tJyXQURXUoIgVypwZ39V0REZB1MDlgFBQVGr5uamlBQUIAVK1Zg4cKFZiuMCAB+rqzD6bpGODspERXiKXc5RERE7WJywOrXr1+rfbGxsQgKCsKyZcswcuRIsxRGBPzefzUg1AtqRweZqyEiImofk+fBupwePXpg37595jodEQAuj0NERNbJ5DtYOp3O6LUQAuXl5Xj++ee5fA6ZVXOLHnnFhoDF/isiIrIeJgcsT0/PVk3uQggEBwfj448/NlthRIfKdKitb4a7syP6dNPIXQ4REVG7mRywduzYYfRaqVTC19cXERERcHTkHEVkPobHgwnh3nBQXv6Xq0RERJ2NyYlIoVAgKSmpVZhqbm7Gd999h8GDB5utOLJvhgZ3Ph4kIiJrY3KT+9ChQ9tcb1Cr1WLo0KFmKYqoobkF+0ou/nM2MIIN7kREZF1MDlhCiDYnGj1z5gy6dOlilqKICktrUN+kh4+bCt393OQuh4iIyCTtfkRomN9KoVBgwoQJUKvV0rGWlhb8+OOPSEpKMn+FZJcuXR7nSisHEBERdUbtDlgazcVfcQkh4O7uDhcXF+mYSqVCQkICHnnkEfNXSHaJy+MQEZE1a3fAWr9+PYCLaxE+9dRTfBxIFnOuoRkFpTUAOMEoERFZJ5N7sBYsWAC1Wo1vvvkGb775JmprawEAZWVlqKurM3uBZH/2lVSjWS/QzdMFwV4uV38DERFRJ2PyNA3/+9//cPvtt6O0tBQNDQ3405/+BHd3d7zyyitoaGhAZmamJeokO5L7W//VwAhv9l8REZFVMvkO1pNPPonY2FicPXvWqA/rb3/7G7Kzs81aHNmnHGn+Kz4eJCIi62TyHaz//ve/2L17N1QqldH+0NBQnDp1ymyFkX2qOd+IQ2UX17tMZIM7ERFZKZPvYOn1erS0tLTaf/LkSbi7u5ulKLJfecXVEAKI8HODv4ez3OUQERFdE5MD1vDhw5GRkSG9VigUqKurw4IFC3DHHXeYszayQ1weh4iIbIHJjwiXL1+OlJQU9OrVC/X19bjvvvtw7Ngx+Pj44KOPPrJEjWRHDAs8s/+KiIismckB64YbbsAPP/yAjRs34ocffkBdXR0mTZqEcePGGTW9E5mqUlePoqo6KBRAQriX3OUQERFdM5MDFgA4Ojpi3LhxGDdunLSvvLwcTz/9NFavXm224si+GKZn6B3kAU9X1VVGExERdV4mBaxDhw5hx44dUKlUuOeee+Dp6YnTp09j4cKFyMzMRHh4uKXqJDuwW1oeh48HiYjIurW7yf3zzz9HdHQ0nnjiCTz22GOIjY3Fjh070LNnTxw+fBifffYZDh06ZMlayYYJIZBTZFjgmQ3uRERk3dodsF5++WWkpaVBp9NhxYoVKC4uxhNPPIGtW7di27ZtuP322y1ZJ9m4E9UXcKrmAhyVCgwIZf8VERFZt3YHrKNHjyItLQ1ubm6YNm0alEolXnvtNQwYMMCS9ZGdMDwejA7xRBf1NbUGEhERdRrtDli1tbXw8PAAADg4OMDFxaVDe64WLlyIpKQkuLq6wtPTs80xpaWlGDFiBFxdXeHn54enn34azc3NRmO+/fZb9O/fH2q1GhEREdiwYUOr86xZswahoaFwdnZGfHw89u7da3S8vr4eaWlp8Pb2hpubG0aNGoXKykpzXapdyvnF8HiQ/VdERGT9TLpV8J///AcajQbAxRnds7OzcfDgQaMxd955p/mqu0RjYyNGjx6NxMRErFu3rtXxlpYWjBgxAgEBAdi9ezfKy8vx4IMPwsnJCYsWLQIAHD9+HCNGjMBjjz2GDz74ANnZ2Xj44YcRGBiIlJQUAMDGjRuRnp6OzMxMxMfHIyMjAykpKTh69Cj8/PwAADNmzMCXX36JTZs2QaPRYOrUqRg5ciRycnIscu22TgiBXKnBnf1XRERkA0Q7KRSKq25KpbK9p7tm69evFxqNptX+rVu3CqVSKSoqKqR9f//734WHh4doaGgQQggxa9Ys0bt3b6P3jRkzRqSkpEiv4+LiRFpamvS6paVFBAUFicWLFwshhKipqRFOTk5i06ZN0pjDhw8LACI3N7fd16HVagUAodVq2/0eW3W0QidufGaL6DF3q6hvapa7HCIiostq7/d3ux8R6vX6q25trVHYUXJzc9G3b1/4+/tL+1JSUqDT6aRfN+bm5iI5OdnofSkpKcjNzQVw8S5Zfn6+0RilUonk5GRpTH5+PpqamozGREZGIiQkRBpDpskpunj3akCoF9SODjJXQ0REdP1sppu4oqLCKFwBkF5XVFRccYxOp8OFCxdw9uxZtLS0tDnmyJEj0jlUKlWrPjB/f3/p77SloaEBDQ0N0mudTmfaBdowLo9DRES2xuTFns1p9uzZUCgUV9wMwcbaLV68GBqNRtqCg4PlLqlTaG7RI6/YELDYf0VERLZB1jtYM2fOxIQJE644pr2/VAwICGj1az/DL/sCAgKk//zjr/0qKyvh4eEBFxcXODg4wMHBoc0xl56jsbERNTU1RnexLh3Tljlz5iA9PV16rdPpGLIAHCrToba+Ge7OjujTTSN3OURERGYha8Dy9fWFr6+vWc6VmJiIhQsXoqqqSvq1X1ZWFjw8PNCrVy9pzNatW43el5WVhcTERACASqVCTEwMsrOzkZqaCuD3X0tOnToVABATEwMnJydkZ2dj1KhRAC7OEVZaWiqdpy1qtRpqtdos12pLDI8HE8K94aBUyFwNERGReVhND1ZpaSmqq6tRWlqKlpYWFBYWAgAiIiLg5uaG4cOHo1evXnjggQewdOlSVFRUYO7cuUhLS5OCzWOPPYbVq1dj1qxZeOihh7B9+3Z88skn+PLLL6W/k56ejvHjxyM2NhZxcXHIyMjAuXPnMHHiRACARqPBpEmTkJ6eDi8vL3h4eGDatGlITExEQkJCh38u1s4wwSgfDxIRkU25lp8onj17Vrz11lti9uzZ4syZM0IIIfLz88XJkyev5XTtMn78eAGg1bZjxw5pTElJifjzn/8sXFxchI+Pj5g5c6ZoamoyOs+OHTtEVFSUUKlUIjw8XKxfv77V31q1apUICQkRKpVKxMXFiby8PKPjFy5cEI8//rjo2rWrcHV1FX/7299EeXm5SdfDaRqEqG9qFj3mbhU3PrNFHK3QyV0OERHRVbX3+1shhBCmBLIff/wRycnJ0Gg0KCkpwdGjRxEeHo65c+eitLQU7733ntlDoC3S6XTQaDTQarXSDPn2Zk/xGYxZmwcfNxX2PZcMhYKPCImIqHNr7/e3yb8iTE9Px4QJE3Ds2DE4OztL+++44w58991311Yt2aVLl8dhuCIiIlticsDat28fJk+e3Gp/t27drjgPFNEfcXkcIiKyVSYHLLVa3eYkmT///LPZfhFItu9cQzMKSmsAcIJRIiKyPSYHrDvvvBMvvvgimpqaAAAKhQKlpaV45plnpGkLiK5mX0k1mvUC3TxdEOzlInc5REREZmVywFq+fDnq6urg5+eHCxcu4NZbb0VERATc3d2xcOFCS9RINij3t/6rgRHe7L8iIiKbY/I8WBqNBllZWdi1axd+/PFH1NXVoX///q0WUSa6khxp/is+HiQiIttzzRONDho0CIMGDTJnLWQnas434lDZxT6+RDa4ExGRDTI5YK1cubLN/QqFAs7OzoiIiMDgwYPh4OBw3cWRbcorroYQQISfG/w9nK/+BiIiIitjcsB67bXX8Ouvv+L8+fPo2rUrAODs2bNwdXWFm5sbqqqqEB4ejh07dnAxY2oTl8chIiJbZ3KT+6JFizBgwAAcO3YMZ86cwZkzZ/Dzzz8jPj4er7/+OkpLSxEQEIAZM2ZYol6yAYYFntl/RUREtsrkO1hz587Fp59+iptuuknaFxERgVdffRWjRo1CcXExli5dyikbqE1VunoUVdVBoQASwr3kLoeIiMgiTL6DVV5ejubm5lb7m5ubpZncg4KCUFtbe/3Vkc0x3L3qHeQBT1eVzNUQERFZhskBa+jQoZg8eTIKCgqkfQUFBZgyZQpuu+02AMCBAwcQFhZmvirJZuyWlsfh40EiIrJdJgesdevWwcvLCzExMVCr1VCr1YiNjYWXlxfWrVsHAHBzc8Py5cvNXixZNyEEcooMCzyzwZ2IiGyXyT1YAQEByMrKwpEjR/Dzzz8DAHr06IEePXpIY4YOHWq+CslmnKi+gFM1F+CoVGBAKPuviIjIdl3zRKORkZGIjIw0Zy1k4wyPB6NDPNFFfc3/6BEREXV61/Qtd/LkSXz++ecoLS1FY2Oj0bEVK1aYpTCyPTm/GB4Psv+KiIhsm8kBKzs7G3feeSfCw8Nx5MgR9OnTByUlJRBCoH///paokWyAEAK5UoM7+6+IiMi2mdzkPmfOHDz11FM4cOAAnJ2d8emnn+LEiRO49dZbMXr0aEvUSDbgWFUdTtc1wtlJiagQT7nLISIisiiTA9bhw4fx4IMPAgAcHR1x4cIFuLm54cUXX8Qrr7xi9gLJNuQUXbx7NSDUC2pHrlNJRES2zeSA1aVLF6nvKjAwEL/88ot07PTp0+arjGwKl8chIiJ7YnIPVkJCAnbt2oWePXvijjvuwMyZM3HgwAH861//QkJCgiVqJCvX3KJHXrEhYLH/ioiIbJ/JAWvFihWoq6sDALzwwguoq6vDxo0b0b17d/6CkNp0qEyH2vpmuDs7ok83jdzlEBERWZxJAaulpQUnT57ELbfcAuDi48LMzEyLFEa2w/B4MCHcGw5KhczVEBERWZ5JPVgODg4YPnw4zp49a6l6yAYZJhjl40EiIrIXJje59+nTB8XFxZaohWxQQ3ML9pVUAwAGRrDBnYiI7IPJAevll1/GU089hS1btqC8vBw6nc5oI7pUYWkN6pv08HFTobufm9zlEBERdQiTm9zvuOMOAMCdd94JheL3fhohBBQKBVpaWsxXHVm9S5fHufSfFyIiIltmcsDasWOHJeogG8XlcYiIyB6ZHLBuvfVWS9RBNuh8YzMKSmsAcIJRIiKyLyb3YAHAf//7X9x///1ISkrCqVOnAAD/+Mc/sGvXLrMWR9Zt7/FqNOsFunm6INjLRe5yiIiIOozJAevTTz9FSkoKXFxcsH//fjQ0NAAAtFotFi1aZPYCyXrl/tZ/NTDCm/1XRERkV67pV4SZmZl466234OTkJO0fOHAg9u/fb9biyLrlSPNf8fEgERHZF5MD1tGjRzF48OBW+zUaDWpqasxRU5sWLlyIpKQkuLq6wtPTs9XxH374AWPHjkVwcDBcXFzQs2dPvP7660Zjvv32WygUilZbRUWF0bg1a9YgNDQUzs7OiI+Px969e42O19fXIy0tDd7e3nBzc8OoUaNQWVlp9mu2ZjXnG3Go7OK0HZxglIiI7I3JASsgIABFRUWt9u/atQvh4eFmKaotjY2NGD16NKZMmdLm8fz8fPj5+eH999/HoUOH8Nxzz2HOnDlYvXp1q7FHjx5FeXm5tPn5+UnHNm7ciPT0dCxYsAD79+9Hv379kJKSgqqqKmnMjBkz8MUXX2DTpk3YuXMnysrKMHLkSPNftBXLK66GEECEnxv8PJzlLoeIiKhjCRMtWrRI9OrVS+Tl5Ql3d3fx3//+V7z//vvC19dXrFy50tTTmWz9+vVCo9G0a+zjjz8uhg4dKr3esWOHACDOnj172ffExcWJtLQ06XVLS4sICgoSixcvFkIIUVNTI5ycnMSmTZukMYcPHxYARG5ubruvQ6vVCgBCq9W2+z3WZN7mA+LGZ7aIeZsPyF0KERGR2bT3+9vkO1izZ8/Gfffdh2HDhqGurg6DBw/Gww8/jMmTJ2PatGnmzn/XRavVwsvLq9X+qKgoBAYG4k9/+hNycnKk/Y2NjcjPz0dycrK0T6lUIjk5Gbm5uQAu3ilramoyGhMZGYmQkBBpDP2+wDP7r4iIyB6ZPA+WQqHAc889h6effhpFRUWoq6tDr1694ObWuZZB2b17NzZu3Igvv/xS2hcYGIjMzEzExsaioaEBb7/9NoYMGYI9e/agf//+OH36NFpaWuDv7290Ln9/fxw5cgQAUFFRAZVK1aoPzN/fv1Uv16UaGhqkX1wCsOllhap09SiqqoNCASSEtw64REREts7kO1jvv/8+zp8/D5VKhV69eiEuLu6aw9Xs2bPbbDq/dDMEG1McPHgQd911FxYsWIDhw4dL+3v06IHJkycjJiYGSUlJeOedd5CUlITXXnvtmuo3xeLFi6HRaKQtODjY4n9TLoa7V72DPODpqpK5GiIioo5ncsCaMWMG/Pz8cN9992Hr1q3XtfbgzJkzcfjw4StupjbO//TTTxg2bBgeffRRzJ0796rj4+LipKZ9Hx8fODg4tPpFYGVlJQICAgBcbPJvbGxs9YvJS8e0Zc6cOdBqtdJ24sQJk67LmuyWlsfh40EiIrJPJj8iLC8vx7Zt2/DRRx/hnnvugaurK0aPHo1x48YhKSnJpHP5+vrC19fX1BIu69ChQ7jtttswfvx4LFy4sF3vKSwsRGBgIABApVIhJiYG2dnZSE1NBQDo9XpkZ2dj6tSpAICYmBg4OTkhOzsbo0aNAnDxV4mlpaVITEy87N9Rq9VQq9XXcXXWQQiBnCLDAs+cnoGIiOyTyQHL0dERf/nLX/CXv/wF58+fx2effYYPP/wQQ4cOxQ033IBffvnFEnWitLQU1dXVKC0tRUtLCwoLCwEAERERcHNzw8GDB3HbbbchJSUF6enpUj+Ug4ODFOIyMjIQFhaG3r17o76+Hm+//Ta2b9+Or7/+Wvo76enpGD9+PGJjYxEXF4eMjAycO3cOEydOBHBxvq9JkyYhPT0dXl5e8PDwwLRp05CYmIiEhASLXLs1OVF9AadqLsBRqcCAUPZfERGRfTI5YF3K1dUVKSkpOHv2LP73v//h8OHD5qqrlfnz5+Pdd9+VXkdHRwMAduzYgSFDhuCf//wnfv31V7z//vt4//33pXE33ngjSkpKAFz8leDMmTNx6tQpuLq64pZbbsE333yDoUOHSuPHjBmDX3/9FfPnz0dFRQWioqKwbds2o8b31157DUqlEqNGjUJDQwNSUlLwxhtvWOzarYnh8WB0iCe6qK/rHy8iIiKrpRBCCFPfZLhz9cEHHyA7OxvBwcEYO3Ysxo0bh8jISEvUaXN0Oh00Gg20Wi08PDzkLsdspn1UgC9+KMMTw7oj/U83y10OERGRWbX3+9vkWwz33nsvtmzZAldXV9xzzz2YN2/eFXuPyH4IIZArNbiz/4qIiOyXyQHLwcEBn3zyCVJSUuDg4GB07ODBg+jTp4/ZiiPrcqyqDqfrGuHspERUiKfc5RAREcnG5ID1wQcfGL2ura3FRx99hLfffhv5+fnXNW0DWbecoot3rwaEekHt6HCV0URERLbL5HmwDL777juMHz8egYGBePXVV3HbbbchLy/PnLWRleHyOERERBeZdAeroqICGzZswLp166DT6XDPPfegoaEBmzdvRq9evSxVI1mBFr1AXrEhYLH/ioiI7Fu772D99a9/RY8ePfDjjz8iIyMDZWVlWLVqlSVrIyty8JQWtfXNcHd2RJ9uGrnLISIiklW772B99dVXeOKJJzBlyhR0797dkjWRFTI8HkwI94aDUiFzNURERPJq9x2sXbt2oba2FjExMYiPj8fq1atx+vRpS9ZGVsQwwSgfDxIREZkQsBISEvDWW2+hvLwckydPxscff4ygoCDo9XpkZWWhtrbWknVSJ9bQ3IJ9JdUAgIERbHAnIiIy+VeEXbp0wUMPPYRdu3bhwIEDmDlzJpYsWQI/Pz/ceeedlqiROrnC0hrUN+nh46ZCdz83ucshIiKS3TVP0wAAPXr0wNKlS3Hy5El89NFH5qqJrEzOb/1XiTf5QKFg/xUREdF1BSwDBwcHpKam4vPPPzfH6cjKcHkcIiIiY2YJWGS/zjc2o6C0BgAnGCUiIjJgwKLrsvd4NZr1At08XRDs5SJ3OURERJ0CAxZdl9zf+q8GRniz/4qIiOg3DFh0XXKk+a/4eJCIiMiAAYuuWc35Rhwq0wHgBKNERESXYsCia5ZXXA0hgAg/N/h5OMtdDhERUafBgEXXjMvjEBERtY0Bi66ZYYFn9l8REREZY8Cia1Klq0dRVR0UCiAh3EvucoiIiDoVBiy6Joa7V72DPODpqpK5GiIios6FAYuuyW5peRw+HiQiIvojBiy6JrulBZ7Z4E5ERPRHDFhkstIz53Hy7AU4KhUYEMr+KyIioj9iwCKTGR4PRod4oovaUeZqiIiIOh8GLDJZjvR4kP1XREREbWHAIpMIIZArNbiz/4qIiKgtDFhkkmNVdThd1whnJyWiQjzlLoeIiKhTYsAik+QUXbx7NSDUC2pHB5mrISIi6pwYsMgkXB6HiIjo6hiwqN1a9AJ5xYaAxf4rIiKiy2HAonY7eEqL2vpmuDs7ok83jdzlEBERdVpWE7AWLlyIpKQkuLq6wtPTs80xCoWi1fbxxx8bjfn222/Rv39/qNVqREREYMOGDa3Os2bNGoSGhsLZ2Rnx8fHYu3ev0fH6+nqkpaXB29sbbm5uGDVqFCorK811qZ2W4fFgQrg3HJQKmashIiLqvKwmYDU2NmL06NGYMmXKFcetX78e5eXl0paamiodO378OEaMGIGhQ4eisLAQ06dPx8MPP4z//Oc/0piNGzciPT0dCxYswP79+9GvXz+kpKSgqqpKGjNjxgx88cUX2LRpE3bu3ImysjKMHDnS7Nfc2RgmGOXjQSIioitTCCGE3EWYYsOGDZg+fTpqampaHVMoFPjss8+MQtWlnnnmGXz55Zc4ePCgtO/ee+9FTU0Ntm3bBgCIj4/HgAEDsHr1agCAXq9HcHAwpk2bhtmzZ0Or1cLX1xcffvgh7r77bgDAkSNH0LNnT+Tm5iIhIaFd16HT6aDRaKDVauHh4WHCJyCPhuYW9Hvha9Q36fH1jMG42d9d7pKIiIg6XHu/v63mDlZ7paWlwcfHB3FxcXjnnXdwaX7Mzc1FcnKy0fiUlBTk5uYCuHiXLD8/32iMUqlEcnKyNCY/Px9NTU1GYyIjIxESEiKNaUtDQwN0Op3RZk0KS2tQ36SHj5sK3f3c5C6HiIioU7OpheRefPFF3HbbbXB1dcXXX3+Nxx9/HHV1dXjiiScAABUVFfD39zd6j7+/P3Q6HS5cuICzZ8+ipaWlzTFHjhyRzqFSqVr1gfn7+6OiouKytS1evBgvvPCCGa5SHpcuj6NQsP+KiIjoSmS9gzV79uw2G9Mv3QzBpj3mzZuHgQMHIjo6Gs888wxmzZqFZcuWWfAK2m/OnDnQarXSduLECblLMgmXxyEiImo/We9gzZw5ExMmTLjimPDw8Gs+f3x8PF566SU0NDRArVYjICCg1a/9Kisr4eHhARcXFzg4OMDBwaHNMQEBAQCAgIAANDY2oqamxugu1qVj2qJWq6FWq6/5WuR0vrEZBaU1ADjBKBERUXvIGrB8fX3h6+trsfMXFhaia9euUrBJTEzE1q1bjcZkZWUhMTERAKBSqRATE4Ps7GypUV6v1yM7OxtTp04FAMTExMDJyQnZ2dkYNWoUAODo0aMoLS2VzmNr9h6vRrNeoJunC4K9XOQuh4iIqNOzmh6s0tJSVFdXo7S0FC0tLSgsLAQAREREwM3NDV988QUqKyuRkJAAZ2dnZGVlYdGiRXjqqaekczz22GNYvXo1Zs2ahYceegjbt2/HJ598gi+//FIak56ejvHjxyM2NhZxcXHIyMjAuXPnMHHiRACARqPBpEmTkJ6eDi8vL3h4eGDatGlITExs9y8IrU3ub/1XAyO82X9FRETUHsJKjB8/XgBote3YsUMIIcRXX30loqKihJubm+jSpYvo16+fyMzMFC0tLUbn2bFjh4iKihIqlUqEh4eL9evXt/pbq1atEiEhIUKlUom4uDiRl5dndPzChQvi8ccfF127dhWurq7ib3/7mygvLzfperRarQAgtFqtSe+Tw19W/lfc+MwW8dn+k3KXQkREJKv2fn9b3TxYtsJa5sGqOd+I6JeyIASw99lh8PNwlrskIiIi2djtPFhkXnnF1RACiPBzY7giIiJqJwYsuiIuj0NERGQ6Biy6IsMCz5yegYiIqP0YsOiyqnT1KKqqg0IBJIR7yV0OERGR1WDAossy3L3qHeQBT1eVzNUQERFZDwYsuqzd0vI4fDxIRERkCgYsuqzd0gLPbHAnIiIyBQMWtan0zHmcPHsBjkoFBoSy/4qIiMgUDFjUJsPjwegQT3RRW82KSkRERJ0CAxa1KUd6PMj+KyIiIlMxYFErQgjkSg3u7L8iIiIyFQMWtXKsqg6n6xrh7KREVIin3OUQERFZHQYsaiWn6OLdqwGhXlA7OshcDRERkfVhwKJWuDwOERHR9WHAIiMteoG8YkPAYv8VERHRtWDAIiMHT2lRW98Md2dH9OmmkbscIiIiq8SARUYMjwcTwr3hoFTIXA0REZF1YsAiI4YJRvl4kIiI6NoxYJGkobkF+0qqAQADI9jgTkREdK0YsEhSWFqD+iY9fNxU6O7nJnc5REREVosBiySXLo+jULD/ioiI6FoxYJGEy+MQERGZBwMWAQDONzajoLQGACcYJSIiul4MWAQA2Hu8Gs16gW6eLgj2cpG7HCIiIqvGgEUAgNzf+q8GRniz/4qIiOg6MWARAK4/SEREZE4MWISa8404WKYFwAlGiYiIzIEBi5BXXA0hgAg/N/h5OMtdDhERkdVjwCIuj0NERGRmDFjE/isiIiIzY8Cyc1W6ehRV1UGhABLCveQuh4iIyCYwYNk5w92r3kEe8HRVyVwNERGRbbCagLVw4UIkJSXB1dUVnp6erY5v2LABCoWiza2qqgoA8O2337Z5vKKiwuhca9asQWhoKJydnREfH4+9e/caHa+vr0daWhq8vb3h5uaGUaNGobKy0mLXbkm7peVx+HiQiIjIXKwmYDU2NmL06NGYMmVKm8fHjBmD8vJyoy0lJQW33nor/Pz8jMYePXrUaNylxzdu3Ij09HQsWLAA+/fvR79+/ZCSkiKFNACYMWMGvvjiC2zatAk7d+5EWVkZRo4caZkLt7Dd0gLPbHAnIiIyF0e5C2ivF154AcDFO1VtcXFxgYvL70u8/Prrr9i+fTvWrVvXaqyfn1+bd8EAYMWKFXjkkUcwceJEAEBmZia+/PJLvPPOO5g9eza0Wi3WrVuHDz/8ELfddhsAYP369ejZsyfy8vKQkJBwHVfZsUrPnMfJsxfgqFQgLoz9V0REROZiNXewTPXee+/B1dUVd999d6tjUVFRCAwMxJ/+9Cfk5ORI+xsbG5Gfn4/k5GRpn1KpRHJyMnJzcwEA+fn5aGpqMhoTGRmJkJAQaYy1MDwejA7xhKvKarI2ERFRp2ezAWvdunW47777jO5qBQYGIjMzE59++ik+/fRTBAcHY8iQIdi/fz8A4PTp02hpaYG/v7/Rufz9/aU+rYqKCqhUqlZ3wC4d05aGhgbodDqjTW6/Px5k/xUREZE5yRqwZs+efdnGdMN25MgRk8+bm5uLw4cPY9KkSUb7e/TogcmTJyMmJgZJSUl45513kJSUhNdee81cl3RZixcvhkajkbbg4GCL/80rEUJIAWsg+6+IiIjMStbnQjNnzsSECROuOCY8PNzk87799tuIiopCTEzMVcfGxcVh165dAAAfHx84ODi0+kVgZWUlAgICAAABAQFobGxETU2N0V2sS8e0Zc6cOUhPT5de63Q6WUPWsao6nK5rgLOTElEhnrLVQUREZItkDVi+vr7w9fU16znr6urwySefYPHixe0aX1hYiMDAQACASqVCTEwMsrOzkZqaCgDQ6/XIzs7G1KlTAQAxMTFwcnJCdnY2Ro0aBeDirxJLS0uRmJh42b+jVquhVquv48rMK6foYv/VgFAvqB0dZK6GiIjItlhNZ3NpaSmqq6tRWlqKlpYWFBYWAgAiIiLg5uYmjdu4cSOam5tx//33tzpHRkYGwsLC0Lt3b9TX1+Ptt9/G9u3b8fXXX0tj0tPTMX78eMTGxiIuLg4ZGRk4d+6c9KtCjUaDSZMmIT09HV5eXvDw8MC0adOQmJhoVb8g5PI4RERElmM1AWv+/Pl49913pdfR0dEAgB07dmDIkCHS/nXr1mHkyJFtTsPQ2NiImTNn4tSpU3B1dcUtt9yCb775BkOHDpXGjBkzBr/++ivmz5+PiooKREVFYdu2bUaN76+99hqUSiVGjRqFhoYGpKSk4I033jD/RVtIi14gr9gQsNh/RUREZG4KIYSQuwh7pNPpoNFooNVq4eHh0aF/+4cTNbhrTQ7cnR1ROH84HJSKDv37RERE1qq93982O00DXZ7h8WBCuDfDFRERkQUwYNkhwwSjfDxIRERkGQxYdqahuQX7SqoBAAMj2OBORERkCQxYdqawtAb1TXr4uKnQ3c/t6m8gIiIikzFg2ZmcS5bHUSjYf0VERGQJDFh2Jve3/isuj0NERGQ5DFh25HxjMwpKawBwglEiIiJLYsCyI3uPV6NZL9DN0wXBXi5yl0NERGSzGLDsSO5v/VcDI7zZf0VERGRBDFh2hOsPEhERdQwGLDtRc74RB8u0ADjBKBERkaUxYNmJvOJqCAFE+LnBz8NZ7nKIiIhsGgOWncjl8jhEREQdhgHLTuSw/4qIiKjDMGDZgSpdPYqq6qBQAAnhXnKXQ0REZPMYsOyA4deDvYM84OmqkrkaIiIi28eAZQd2S8vj8PEgERFRR2DAsgO7pQWe2eBORETUERiwbFzpmfM4efYCHJUKxIWx/4qIiKgjMGDZOMPjwegQT7iqHGWuhoiIyD4wYNm43x8Psv+KiIioozBg2TAhhBSwBrL/ioiIqMMwYNmwY1V1OF3XAGcnJaJCPOUuh4iIyG4wYNmwnKKL/VcDQr2gdnSQuRoiIiL7wYBlw3ZzeRwiIiJZMGDZqBa9QF6xIWCx/4qIiKgjMWDZqIOntKitb4a7syP6dNPIXQ4REZFdYcCyUYbHgwnh3nBQKmSuhoiIyL4wYNkowwSjfDxIRETU8RiwbFBDcwv2lVQDAAZGsMGdiIioozFg2aDC0hrUN+nh46ZCdz83ucshIiKyOwxYNujS5XEUCvZfERERdTQGLBtk6L/i8jhERETysIqAVVJSgkmTJiEsLAwuLi646aabsGDBAjQ2NhqN+/HHH/F///d/cHZ2RnBwMJYuXdrqXJs2bUJkZCScnZ3Rt29fbN261ei4EALz589HYGAgXFxckJycjGPHjhmNqa6uxrhx4+Dh4QFPT09MmjQJdXV15r/wa3C+sRkFpTUAOMEoERGRXKwiYB05cgR6vR5vvvkmDh06hNdeew2ZmZl49tlnpTE6nQ7Dhw/HjTfeiPz8fCxbtgzPP/881q5dK43ZvXs3xo4di0mTJqGgoACpqalITU3FwYMHpTFLly7FypUrkZmZiT179qBLly5ISUlBfX29NGbcuHE4dOgQsrKysGXLFnz33Xd49NFHO+bDuIq9x6vRrBfo5umCYC8XucshIiKyT8JKLV26VISFhUmv33jjDdG1a1fR0NAg7XvmmWdEjx49pNf33HOPGDFihNF54uPjxeTJk4UQQuj1ehEQECCWLVsmHa+pqRFqtVp89NFHQgghfvrpJwFA7Nu3Txrz1VdfCYVCIU6dOtXu+rVarQAgtFptu9/THou+/Enc+MwW8fSmQrOel4iIiNr//W0Vd7DaotVq4eXlJb3Ozc3F4MGDoVKppH0pKSk4evQozp49K41JTk42Ok9KSgpyc3MBAMePH0dFRYXRGI1Gg/j4eGlMbm4uPD09ERsbK41JTk6GUqnEnj17LltvQ0MDdDqd0WYJXH+QiIhIflYZsIqKirBq1SpMnjxZ2ldRUQF/f3+jcYbXFRUVVxxz6fFL33e5MX5+fkbHHR0d4eXlJY1py+LFi6HRaKQtODi43ddrisUj++LZOyI5/xUREZGMZA1Ys2fPhkKhuOJ25MgRo/ecOnUKt99+O0aPHo1HHnlEpspNN2fOHGi1Wmk7ceKERf5On24aPDr4Jvi6qy1yfiIiIro6Rzn/+MyZMzFhwoQrjgkPD5f+e1lZGYYOHYqkpCSj5nUACAgIQGVlpdE+w+uAgIArjrn0uGFfYGCg0ZioqChpTFVVldE5mpubUV1dLb2/LWq1Gmo1Qw8REZE9kPUOlq+vLyIjI6+4GXqqTp06hSFDhiAmJgbr16+HUmlcemJiIr777js0NTVJ+7KystCjRw907dpVGpOdnW30vqysLCQmJgIAwsLCEBAQYDRGp9Nhz5490pjExETU1NQgPz9fGrN9+3bo9XrEx8eb8dMhIiIiq9VBTffX5eTJkyIiIkIMGzZMnDx5UpSXl0ubQU1NjfD39xcPPPCAOHjwoPj444+Fq6urePPNN6UxOTk5wtHRUbz66qvi8OHDYsGCBcLJyUkcOHBAGrNkyRLh6ekp/v3vf4sff/xR3HXXXSIsLExcuHBBGnP77beL6OhosWfPHrFr1y7RvXt3MXbsWJOuyVK/IiQiIiLLae/3t1UErPXr1wsAbW6X+uGHH8SgQYOEWq0W3bp1E0uWLGl1rk8++UTcfPPNQqVSid69e4svv/zS6Lherxfz5s0T/v7+Qq1Wi2HDhomjR48ajTlz5owYO3ascHNzEx4eHmLixImitrbWpGtiwCIiIrI+7f3+VgghhFx3z+yZTqeDRqOBVquFh4eH3OUQERFRO7T3+9sqp2kgIiIi6swYsIiIiIjMjAGLiIiIyMwYsIiIiIjMjAGLiIiIyMwYsIiIiIjMjAGLiIiIyMwYsIiIiIjMjAGLiIiIyMwc5S7AXhkm0NfpdDJXQkRERO1l+N6+2kI4DFgyqa2tBQAEBwfLXAkRERGZqra2FhqN5rLHuRahTPR6PcrKyuDu7g6FQmG28+p0OgQHB+PEiRNc49DC+Fl3DH7OHYOfc8fg59wxLPk5CyFQW1uLoKAgKJWX77TiHSyZKJVK3HDDDRY7v4eHB/+ft4Pws+4Y/Jw7Bj/njsHPuWNY6nO+0p0rAza5ExEREZkZAxYRERGRmTFg2Ri1Wo0FCxZArVbLXYrN42fdMfg5dwx+zh2Dn3PH6AyfM5vciYiIiMyMd7CIiIiIzIwBi4iIiMjMGLCIiIiIzIwBy8asWbMGoaGhcHZ2Rnx8PPbu3St3STZl8eLFGDBgANzd3eHn54fU1FQcPXpU7rJs3pIlS6BQKDB9+nS5S7E5p06dwv333w9vb2+4uLigb9+++P777+Uuy+a0tLRg3rx5CAsLg4uLC2666Sa89NJLV11uha7su+++w1//+lcEBQVBoVBg8+bNRseFEJg/fz4CAwPh4uKC5ORkHDt2rENqY8CyIRs3bkR6ejoWLFiA/fv3o1+/fkhJSUFVVZXcpdmMnTt3Ii0tDXl5ecjKykJTUxOGDx+Oc+fOyV2azdq3bx/efPNN3HLLLXKXYnPOnj2LgQMHwsnJCV999RV++uknLF++HF27dpW7NJvzyiuv4O9//ztWr16Nw4cP45VXXsHSpUuxatUquUuzaufOnUO/fv2wZs2aNo8vXboUK1euRGZmJvbs2YMuXbogJSUF9fX1li9OkM2Ii4sTaWlp0uuWlhYRFBQkFi9eLGNVtq2qqkoAEDt37pS7FJtUW1srunfvLrKyssStt94qnnzySblLsinPPPOMGDRokNxl2IURI0aIhx56yGjfyJEjxbhx42SqyPYAEJ999pn0Wq/Xi4CAALFs2TJpX01NjVCr1eKjjz6yeD28g2UjGhsbkZ+fj+TkZGmfUqlEcnIycnNzZazMtmm1WgCAl5eXzJXYprS0NIwYMcLon2syn88//xyxsbEYPXo0/Pz8EB0djbfeekvusmxSUlISsrOz8fPPPwMAfvjhB+zatQt//vOfZa7Mdh0/fhwVFRVG//7QaDSIj4/vkO9FrkVoI06fPo2Wlhb4+/sb7ff398eRI0dkqsq26fV6TJ8+HQMHDkSfPn3kLsfmfPzxx9i/fz/27dsndyk2q7i4GH//+9+Rnp6OZ599Fvv27cMTTzwBlUqF8ePHy12eTZk9ezZ0Oh0iIyPh4OCAlpYWLFy4EOPGjZO7NJtVUVEBAG1+LxqOWRIDFtE1SktLw8GDB7Fr1y65S7E5J06cwJNPPomsrCw4OzvLXY7N0uv1iI2NxaJFiwAA0dHROHjwIDIzMxmwzOyTTz7BBx98gA8//BC9e/dGYWEhpk+fjqCgIH7WNoqPCG2Ej48PHBwcUFlZabS/srISAQEBMlVlu6ZOnYotW7Zgx44duOGGG+Qux+bk5+ejqqoK/fv3h6OjIxwdHbFz506sXLkSjo6OaGlpkbtEmxAYGIhevXoZ7evZsydKS0tlqsh2Pf3005g9ezbuvfde9O3bFw888ABmzJiBxYsXy12azTJ898n1vciAZSNUKhViYmKQnZ0t7dPr9cjOzkZiYqKMldkWIQSmTp2Kzz77DNu3b0dYWJjcJdmkYcOG4cCBAygsLJS22NhYjBs3DoWFhXBwcJC7RJswcODAVtOM/Pzzz7jxxhtlqsh2nT9/Hkql8Veug4MD9Hq9TBXZvrCwMAQEBBh9L+p0OuzZs6dDvhf5iNCGpKenY/z48YiNjUVcXBwyMjJw7tw5TJw4Ue7SbEZaWho+/PBD/Pvf/4a7u7v0HF+j0cDFxUXm6myHu7t7q762Ll26wNvbm/1uZjRjxgwkJSVh0aJFuOeee7B3716sXbsWa9eulbs0m/PXv/4VCxcuREhICHr37o2CggKsWLECDz30kNylWbW6ujoUFRVJr48fP47CwkJ4eXkhJCQE06dPx8svv4zu3bsjLCwM8+bNQ1BQEFJTUy1fnMV/p0gdatWqVSIkJESoVCoRFxcn8vLy5C7JpgBoc1u/fr3cpdk8TtNgGV988YXo06ePUKvVIjIyUqxdu1bukmySTqcTTz75pAgJCRHOzs4iPDxcPPfcc6KhoUHu0qzajh072vx38vjx44UQF6dqmDdvnvD39xdqtVoMGzZMHD16tENqUwjBaWSJiIiIzIk9WERERERmxoBFREREZGYMWERERERmxoBFREREZGYMWERERERmxoBFREREZGYMWERERERmxoBFREREZGYMWEREHSQ0NBQZGRlyl0FEHYABi4hs0oQJE6T1xoYMGYLp06d32N/esGEDPD09W+3ft28fHn300Q6rg4jkw8WeiYjaqbGxESqV6prf7+vra8ZqiKgz4x0sIrJpEyZMwM6dO/H6669DoVBAoVCgpKQEAHDw4EH8+c9/hpubG/z9/fHAAw/g9OnT0nuHDBmCqVOnYvr06fDx8UFKSgoAYMWKFejbty+6dOmC4OBgPP7446irqwMAfPvtt5g4cSK0Wq30955//nkArR8RlpaW4q677oKbmxs8PDxwzz33oLKyUjr+/PPPIyoqCv/4xz8QGhoKjUaDe++9F7W1tdKYf/7zn+jbty9cXFzg7e2N5ORknDt3zkKfJhG1FwMWEdm0119/HYmJiXjkkUdQXl6O8vJyBAcHo6amBrfddhuio6Px/fffY9u2baisrMQ999xj9P53330XKpUKOTk5yMzMBAAolUqsXLkShw4dwrvvvovt27dj1qxZAICkpCRkZGTAw8ND+ntPPfVUq7r0ej3uuusuVFdXY+fOncjKykJxcTHGjBljNO6XX37B5s2bsWXLFmzZsgU7d+7EkiVLAADl5eUYO3YsHnroIRw+fBjffvstRo4cCSGEJT5KIjIBHxESkU3TaDRQqVRwdXVFQECAtH/16tWIjo7GokWLpH3vvPMOgoOD8fPPP+Pmm28GAHTv3h1Lly41Ouel/VyhoaF4+eWX8dhjj+GNN96ASqWCRqOBQqEw+nt/lJ2djQMHDuD48eMIDg4GALz33nvo3bs39u3bhwEDBgC4GMQ2bNgAd3d3AMADDzyA7OxsLFy4EOXl5WhubsbIkSNx4403AgD69u17HZ8WEZkL72ARkV364YcfsGPHDri5uUlbZGQkgIt3jQxiYmJavfebb77BsGHD0K1bN7i7u+OBBx7AmTNncP78+Xb//cOHDyM4OFgKVwDQq1cveHp64vDhw9K+0NBQKVwBQGBgIKqqqgAA/fr1w7Bhw9C3b1+MHj0ab731Fs6ePdv+D4GILIYBi4jsUl1dHf7617+isLDQaDt27BgGDx4sjevSpYvR+0pKSvCXv/wFt9xyCz799FPk5+djzZo1AC42wZubk5OT0WuFQgG9Xg8AcHBwQFZWFr766iv06tULq1atQo8ePXD8+HGz10FEpmHAIiKbp1Kp0NLSYrSvf//+OHToEEJDQxEREWG0/TFUXSo/Px96vR7Lly9HQkICbr75ZpSVlV317/1Rz549ceLECZw4cULa99NPP6Gmpga9evVq97UpFAoMHDgQL7zwAgoKCqBSqfDZZ5+1+/1EZBkMWERk80JDQ7Fnzx6UlJTg9OnT0Ov1SEtLQ3V1NcaOHYt9+/bhl19+wX/+8x9MnDjxiuEoIiICTU1NWLVqFYqLi/GPf/xDan6/9O/V1dUhOzsbp0+fbvPRYXJyMvr27Ytx48Zh//792Lt3Lx588EHceuutiI2Nbdd17dmzB4sWLcL333+P0tJS/Otf/8Kvv/6Knj17mvYBEZHZMWARkc176qmn4ODggF69esHX1xelpaUICgpCTk4OWlpaMHz4cPTt2xfTp0+Hp6cnlMrL/6uxX79+WLFiBV555RX06dMHH3zwARYvXmw0JikpCY899hjGjBkDX1/fVk3ywMU7T//+97/RtWtXDB48GMnJyQgPD8fGjRvbfV0eHh747rvvcMcdd+Dmm2/G3LlzsXz5cvz5z39u/4dDRBahEPw9LxEREZFZ8Q4WERERkZkxYBERERGZGQMWERERkZkxYBERERGZGQMWERERkZkxYBERERGZGQMWERERkZkxYBERERGZGQMWERERkZkxYBERERGZGQMWERERkZkxYBERERGZ2f8DKtMoR5YRsD4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "class TradingSimulator:\n",
        "    def __init__(self, env, eval_env, agent, episodes=EPISODES, batch_size=BATCH_SIZE, num_eval_episodes=TEST_INTERVALS, collect_steps_per_iteration=INIT_COLLECT, replay_buffer_max_length=MEMORY_LENGTH , num_iterations = TOTAL_ITERS, log_interval=LOG_INTERVALS, eval_interval=TEST_INTERVALS):\n",
        "        self.py_env = env\n",
        "        self.env =  tf_py_environment.TFPyEnvironment(self.py_env)\n",
        "        self.py_eval_env = eval_env\n",
        "        self.eval_env =  tf_py_environment.TFPyEnvironment(self.py_eval_env)\n",
        "        self.agent = agent\n",
        "        self.episodes = episodes\n",
        "        self.log_interval = log_interval\n",
        "        self.eval_interval = eval_interval\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.num_eval_episodes = num_eval_episodes\n",
        "        self.collect_steps_per_iteration = collect_steps_per_iteration\n",
        "        self.replay_buffer_max_length = replay_buffer_max_length\n",
        "        self.num_iterations = num_iterations\n",
        "\n",
        "        self.policy = self.agent.policy\n",
        "        self.collect_policy = self.agent.collect_policy\n",
        "        self.random_policy = random_tf_policy.RandomTFPolicy(\n",
        "            self.env.time_step_spec(),\n",
        "            self.env.action_spec())\n",
        "\n",
        "        self.replay_buffer_signature = tensor_spec.from_spec(\n",
        "            self.agent.collect_data_spec)\n",
        "        self.replay_buffer_signature = tensor_spec.add_outer_dim(\n",
        "            self.replay_buffer_signature)\n",
        "\n",
        "    def compute_avg_return(self, environment, policy, num_eval_episodes):\n",
        "        total_return = 0.0\n",
        "        for _ in range(num_eval_episodes):\n",
        "            time_step = self.env.reset()\n",
        "            episode_return = 0.0\n",
        "\n",
        "            while not time_step.is_last():\n",
        "                action_step = policy.action(time_step)\n",
        "                time_step = environment.step(action_step.action)\n",
        "                episode_return += time_step.reward\n",
        "                total_return += episode_return\n",
        "\n",
        "        avg_return = total_return / self.episodes\n",
        "        return avg_return.numpy()[0]\n",
        "\n",
        "    def init_memory(self, table_name = 'uniform_table'):\n",
        "        self.table = reverb.Table(\n",
        "            table_name,\n",
        "            max_size=self.replay_buffer_max_length,\n",
        "            sampler=reverb.selectors.Uniform(),\n",
        "            remover=reverb.selectors.Fifo(),\n",
        "            rate_limiter=reverb.rate_limiters.MinSize(1),\n",
        "            signature=self.replay_buffer_signature)\n",
        "\n",
        "        self.reverb_server = reverb.Server([self.table])\n",
        "        self.replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
        "                                    self.agent.collect_data_spec,\n",
        "                                    table_name=table_name,\n",
        "                                    sequence_length=2,\n",
        "                                    local_server=self.reverb_server)\n",
        "\n",
        "        self.rb_observer = reverb_utils.ReverbAddTrajectoryObserver(self.replay_buffer.py_client, table_name, sequence_length=2)\n",
        "\n",
        "        print(self.agent.collect_data_spec)\n",
        "        print(self.agent.collect_data_spec._fields)\n",
        "\n",
        "        # Random collections to init and test\n",
        "        py_driver.PyDriver(\n",
        "            self.py_env,\n",
        "            py_tf_eager_policy.PyTFEagerPolicy(self.random_policy, True),\n",
        "            [self.rb_observer],\n",
        "            max_steps=self.collect_steps_per_iteration).run(self.py_env.reset())\n",
        "\n",
        "        time_step = self.env.reset()\n",
        "        print(time_step)\n",
        "        print(self.random_policy.action(time_step))\n",
        "\n",
        "        self.compute_avg_return(self.eval_env, self.random_policy, self.num_eval_episodes)\n",
        "\n",
        "        self.dataset = self.replay_buffer.as_dataset(num_parallel_calls=3, sample_batch_size=self.batch_size, num_steps=2).prefetch(3)\n",
        "\n",
        "        iterator = iter(self.dataset)\n",
        "        print(iterator)\n",
        "\n",
        "        return self.dataset, iterator\n",
        "\n",
        "    def train(self):\n",
        "        _, iterator = self.init_memory()\n",
        "\n",
        "        self.agent.train = common.function(self.agent.train)\n",
        "        self.agent.train_step_counter.assign(0)\n",
        "\n",
        "        # Agent's first eval\n",
        "        avg_return = self.compute_avg_return(self.eval_env, self.agent.policy, self.num_eval_episodes)\n",
        "        returns = [avg_return]\n",
        "        time_step = self.py_env.reset()\n",
        "        collect_driver = py_driver.PyDriver(\n",
        "            self.py_env,\n",
        "            py_tf_eager_policy.PyTFEagerPolicy(self.agent.collect_policy, use_tf_function=True),\n",
        "            [self.rb_observer],\n",
        "            max_steps=self.collect_steps_per_iteration)\n",
        "\n",
        "        for _ in tqdm(range(self.num_iterations), desc=\"Training Loop\"):\n",
        "            time_step, _ = collect_driver.run(time_step)\n",
        "            experience, _ = next(iterator)\n",
        "            train_loss = self.agent.train(experience).loss\n",
        "\n",
        "            step = self.agent.train_step_counter.numpy()\n",
        "\n",
        "            if step % self.log_interval == 0:\n",
        "                print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "            if step % self.eval_interval == 0:\n",
        "                avg_return = self.compute_avg_return(self.eval_env, self.agent.policy, self.num_eval_episodes)\n",
        "                print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "                returns.append(avg_return)\n",
        "\n",
        "        print(f'\\nTraining completed. Mean Reward: {np.mean(returns):.4f}, Mean Loss: {np.mean(train_loss):.4f}')\n",
        "\n",
        "        return returns\n",
        "\n",
        "    def get_policy_eval(self, num_episodes=5):\n",
        "        results = []\n",
        "        for _ in range(num_episodes):\n",
        "            time_step = self.eval_env.reset()\n",
        "            results.append(self.eval_py_env.render())\n",
        "            while not time_step.is_last():\n",
        "                action_step = self.random_policy.action(time_step)\n",
        "                time_step = self.eval_env.step(action_step.action)\n",
        "                results.append(self.py_eval_env.render())\n",
        "\n",
        "        return results\n",
        "\n",
        "    def plot_performance(self, returns):\n",
        "        \"\"\"\n",
        "        Plot the training performance including rewards and losses.\n",
        "        \"\"\"\n",
        "        iterations = range(0, self.num_iterations + 1, self.eval_interval)\n",
        "        plt.plot(iterations, returns)\n",
        "        plt.ylabel('Average Return')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylim(top=250)\n",
        "\n",
        "sim = TradingSimulator(train_env, test_env, agent=agent)\n",
        "returns = sim.train()\n",
        "sim.plot_performance(returns)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(model=q_net)\n",
        "checkpoint.save(f'{MODELS_PATH}/dqn_trained.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTeb9dL6H0Cu"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "CONCLUDE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBrMDUgZH0Cv"
      },
      "source": [
        "## References\n",
        "\n",
        "- [TensorFlow Agents](https://www.tensorflow.org/agents/overview)\n",
        "- [Open Gym AI Github](https://github.com/openai/gym)\n",
        "- [Greg et al, OpenAI Gym, (2016)](https://arxiv.org/abs/1606.01540)\n",
        "- [Théate, Thibaut, and Damien Ernst. \"An application of deep reinforcement learning to algorithmic trading.\" Expert Systems with Applications 173 (2021): 114632.](https://www.sciencedirect.com/science/article/pii/S0957417421000737)\n",
        "- [Remote development in WSL](https://code.visualstudio.com/docs/remote/wsl-tutorial)\n",
        "- [NVIDIA Driver Downloads](https://www.nvidia.com/Download/index.aspx)\n",
        "- [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit-archive)\n",
        "- [TensorRT for CUDA](https://docs.nvidia.com/deeplearning/tensorrt/archives/index.html#trt_7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIgjl92lH0Cv"
      },
      "source": [
        "## Github\n",
        "\n",
        "Article here is also available on [Github](https://github.com/adamd1985/pairs_trading_unsupervised_learning)\n",
        "\n",
        "Kaggle notebook available [here](https://www.kaggle.com/code/addarm/unsupervised-learning-as-signals-for-pairs-trading)\n",
        "\n",
        "## Media\n",
        "\n",
        "All media used (in the form of code or images) are either solely owned by me, acquired through licensing, or part of the Public Domain and granted use through Creative Commons License.\n",
        "\n",
        "## CC Licensing and Use\n",
        "\n",
        "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}